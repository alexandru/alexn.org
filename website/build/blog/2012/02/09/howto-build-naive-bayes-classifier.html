<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/Article">
<head>
  
    <title>How To Build a Naive Bayes Classifier</title>
  

  <meta charset="utf-8">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width,initial-scale=1">

  <link rel="canonical" href="https://www.bionicspirit.com/blog/2012/02/09/howto-build-naive-bayes-classifier.html">

  <link rel="alternate"  href="/atom.xml" title="Alexandru Nedelcu" type="application/atom+xml">
  <link href="../../../../assets/css/all-aa1a19d2.css" media="screen" rel="stylesheet" type="text/css" />

  <!-- Google+ / Facebook optimations -->
  <link rel="image_src" href="../../../../img/picture_alex.jpg">
  <!-- not really sure about this -->
  <link href="https://plus.google.com/112639155372207976835/" rel="publisher">
  <link href="https://plus.google.com/112639155372207976835/" rel="author">
  <!-- END: Google+ / Facebook optimations -->

  <!-- Google Analytics -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27605864-1']);
  _gaq.push(['_setDomainName', 'bionicspirit.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
  
</head>
<body>
  <div id="header-container">
    <header>
      <h1 id="title">Bionic Spirit</h1>

      <nav>
	  <a href="/">bionicspirit.com</a>
	  <a class="extra" href="/pages/archive.html">archive</a>
	  <a class="extra" href="/pages/about.html">about</a>
	  <a href="https://github.com/alexandru" class="github" title="Fork me on GitHub"><span>Fork me on GitHub</span></a>
      </nav>
    </header>
  </div>

  <div id="main-container">
    <div id="main">
      <article id="post">
  <header>
    <h1 itemprop="name">How To Build a Naive Bayes Classifier</h1>
    <div id="meta">
      <div class="post-date">Feb 09, 2012</div>
    </div>
  </header>

  <div id="content">
    <p>Some use-cases for building a classifier:</p>

<ul>
<li>Spam detection, for example you could build your own
<a href="http://akismet.com/">Akismet</a> API</li>
<li>Automatic assignment of categories to a set of items</li>
<li>Automatic detection of the primary language (e.g. Google Translate)</li>
<li>Sentiment analysis, which in simple terms refers to discovering if
an opinion is about love or hate about a certain topic</li>
</ul>

<p>In general you can do a lot better with more specialized techniques,
however the Naive Bayes classifier is general-purpose, simple to
implement and good-enough for most applications. And while other
algorithms give better accuracy, in general I discovered that having
better data in combination with an algorithm that you can tweak does
give better results for less effort.</p>

<p>In this article I&#39;m describing the math behind it. Don&#39;t fear the
math, as this is simple enough that a high-schooler understands. And
even though there are a lot of libraries out there that already do
this, you&#39;re far better off for understanding the concept behind it,
otherwise you won&#39;t be able to tweak the implementation in response to
your needs.</p>

<h2>0. The Source Code</h2>

<p>I published the source-code associated at
<a href="https://github.com/alexandru/stuff-classifier">github.com/alexandru/stuff-classifier</a>. The
implementation itself is at
<a href="https://github.com/alexandru/stuff-classifier/blob/master/lib/stuff-classifier/bayes.rb">lib/bayes.rb</a>,
with the corresponding
<a href="https://github.com/alexandru/stuff-classifier/blob/master/test/test_002_naive_bayes.rb">test/test<em>002</em>naive_bayes.rb</a>.</p>

<h2>1. Introduction to Probabilities</h2>

<p>Let&#39;s start by refreshing forgotten knowledge. Again, this is very
basic stuff, but if you can&#39;t follow the theory here, you can always
go to the
<a href="http://www.khanacademy.org/#probability">probabilities section on khanacademy.org</a>.</p>

<h3>1.1. Events and Event Types</h3>

<p>An &ldquo;event&rdquo; is a set of outcomes (a subset of all possible outcomes)
with a probability attached. So when flipping a coin, we can have one
of these 2 events happening: tail or head. Each of them has a
probability of 50%. Using a Venn diagram, this would look like this:</p>

<p><img class="center" supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="414" height="218" src="../../../../assets/img/coin-flip-bbdc392d.png" />
And another example which clearly shows the <em>dependence</em> between
&ldquo;rain&rdquo; and &ldquo;cloud formation&rdquo;, as raining can only happen if there are
clouds:</p>

<p><img class="center" supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="432" height="273" src="../../../../assets/img/inclusive-29d505fc.png" />
The relationship between events is very important, as you&#39;ll see next:</p>

<ul>
<li>2 events are <strong>disjoint (exclusive)</strong> if they can&#39;t happen at the same
time (a single coin flip cannot yield a tail and a head at the same
time). For Bayes classification, we are not concerned with disjoint
events. </li>
<li>2 events are <strong>independent</strong> when they can happen at the same time,
but the occurrence of one event does not make the occurrence of
another more or less probable. For example the second coin-flip you
make is not affected by the outcome of the first coin-flip.<br></li>
<li>2 events are <strong>dependent</strong> if the outcome of one affects the other. In
the example above, clearly it cannot rain without a cloud
formation. Also, in a horse race, some horses have better
performance on rainy days.</li>
</ul>

<p>What we are concerned here is the difference between dependent and
independent events, because calculating the intersection (both
happening at the same time) depends on it. So for independent events,
calculating the intersection is easy:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="214" height="36" src="../../../../assets/img/independent-events-intersection-30a5066b.png" /></p>

<p>Some examples:</p>

<ul>
<li>if you have 2 hard-drives, each of them having a 0.3 (30%)
probability of failure within the next year, that means there&#39;s a
0.09 (9%) probability of them failing both within the next year</li>
<li>if you flip a coin 4 times, there&#39;s a 0.0625 probability of getting
a tail 4 times in a row (0.5 ^ 4)</li>
</ul>

<p>Things are not so simple for dependent events, which is where the
Bayes Theorem comes into play.</p>

<h3>1.2. Conditional Probabilities and The Bayes Theorem</h3>

<p>Let&#39;s take one example. So we have the following stats:</p>

<ul>
<li>30 emails out of a total of 74 are spam messages</li>
<li>51 emails out of those 74 contain the word &ldquo;penis&rdquo;</li>
<li>20 emails containing the word &ldquo;penis&rdquo; have been marked as spam</li>
</ul>

<p>So the question is: what is the probability that the latest received
email is a spam message, given that it contains the word &ldquo;penis&rdquo;?</p>

<p>So these 2 events are clearly dependent, which is why you must use the
simple form of the Bayes Theorem:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="490" height="272" src="../../../../assets/img/conditional-prob-9a27ee0e.png" /></p>

<p>With the solution being:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="415" height="199" src="../../../../assets/img/spam-simple-bayes-d57fa7ac.png" /></p>

<p>This was a simple one, you could definitely see the result without
complicating yourself with the Bayes formula.</p>

<h3>1.3. The Naive Bayes Approach</h3>

<p>Let us complicate the problem above by adding to it:</p>

<ul>
<li>25 emails out of the total contain the word &ldquo;viagra&rdquo;</li>
<li>24 emails out of those have been marked as spam</li>
<li>so what&#39;s the probability that an email is spam, given that it
contains both &ldquo;viagra&rdquo; and &ldquo;penis&rdquo;?</li>
</ul>

<p>Shit just got more complicated, because now the formula is this one:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="467" height="68" src="../../../../assets/img/spam-multiple-bayes-5ca2d76e.png" /></p>

<p>And you definitely don&#39;t want to bother with it if we keep adding
words. But what if we simplified our assumptions and just say that the
occurrence of <em>penis</em> is totally independent from the occurrence of
<em>viagra</em>? Then the formula just got much simpler:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="407" height="250" src="../../../../assets/img/spam-multiple-bayes-naive-461655a0.png" /></p>

<p>To classify an email as spam, you&#39;ll have to calculate the conditional
probability by taking hints from the words contained. And the Naive
Bayes approach is exactly what I described above: we make the
assumption that the occurrence of one word is totally unrelated to the
occurrence of another, to simplify the processing and complexity
involved.</p>

<p>This does highlight the flaw of this method of classification, because
clearly those 2 events we&#39;ve picked (viagra and penis) are correlated
and our assumption is wrong. But this just means our results will be
less accurate.</p>

<h2>2. Implementation</h2>

<p>I mention it again, you can take a look at the source-code published
at
<a href="https://github.com/alexandru/stuff-classifier/">github.com/alexandru/stuff-classifier</a>.</p>

<h3>2.1. General Algorithm</h3>

<p>You simply get the probability for a text to belong to each of the
categories you test against. The category with the highest probability
for the given text wins:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="588" height="70" src="../../../../assets/img/bayes-classifier-formula-9612a4f9.png" /></p>

<p>Do note that above I also eliminated the <em>denominator</em> from our original
formula, because it is a constant that we do not need (called
<em>evidence</em>).</p>

<h3>2.2. Avoiding Floating Point Underflow (UPDATE Feb 27, 2012)</h3>

<p>Because of the underlying limits of floating points, if you&#39;re working
with big documents (not the case in this example), you do have to make
one important optimization to the above formula:</p>

<ul>
<li>instead of the probabilities of each word, you store the (natural)
logarithms of those probabilities </li>
<li>instead of multiplying the numbers, you add them instead</li>
</ul>

<p>So instead of the above formula, if you need this optimization, then
use this one:</p>

<p><img supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" alt="" width="703" height="67" src="../../../../assets/img/bayes-logarithms-ea324735.png" /></p>

<h3>2.3. Training</h3>

<p>Your implementation must have a training method. Here&#39;s how mine looks like:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
  <span class="n">each_word</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="p">{</span><span class="o">|</span><span class="n">w</span><span class="o">|</span> <span class="n">increment_word</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span> <span class="p">}</span>
  <span class="n">increment_cat</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
<p>And its usage:</p>
<div class="highlight"><pre><span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:spam</span><span class="p">,</span> <span class="s2">&quot;Grow your penis to 20 inches in just 1 week&quot;</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">train</span> <span class="ss">:ham</span><span class="p">,</span>  <span class="s2">&quot;I&#39;m hungry, no I don&#39;t want your penis&quot;</span>
</pre></div>
<p>For the full implementation, take a look at
<a href="https://github.com/alexandru/stuff-classifier/blob/master/lib/stuff-classifier/base.rb">base.rb</a>.</p>

<h3>2.4. Getting Rid of Stop Words / Stemming</h3>

<p>First of all, you must get rid of the junk. Every language has words
that are so commonly used that make them meaningless for any kind of
classification you may want to do. For instance in English you have
words such as &ldquo;the&rdquo;, &ldquo;to&rdquo;, &ldquo;you&rdquo;, &ldquo;he&rdquo;, &ldquo;only&rdquo;, &ldquo;if&rdquo;, &ldquo;it&rdquo; that you
can safely strip out from the text.</p>

<p>I&#39;ve compiled a list of such words in this file:
<a href="https://github.com/alexandru/stuff-classifier/blob/master/lib/stuff-classifier/stop_words.rb">stop_words.rb</a>. You
can compile such a list by yourself if you&#39;re not using English for
example. Head over to <a href="http://www.gutenberg.org/">Project Gutenberg</a>,
download some books in the language you want, count the words in them,
sort by popularity in descending order and keep the top words as words
that you can safely ignore.</p>

<p>Also, our classifier is really dumb in the sense that it does not care
about the meaning or context of a word. So there&#39;s a problem: consider
the word &ldquo;running&rdquo;. What you want is to treat this just as &ldquo;run&rdquo;,
which is the morphological root of the word. You also want to treat
&ldquo;parenting&rdquo; and &ldquo;parents&rdquo; as &ldquo;parent&rdquo;.</p>

<p>This process is called <em>stemming</em> and there are lots of libraries for
it. I think currently the most up-to-date and comprehensive library
for stemming is Snowball. It&#39;s a C library with lots of bindings
available, including for Ruby and Python and it even has support for
my native language (Romanian).</p>

<p>Take a look at what I&#39;m doing in
<a href="https://github.com/alexandru/stuff-classifier/blob/master/lib/stuff-classifier/tokenizer.rb">tokenizer.rb</a>,
where I&#39;m getting rid of stop words and stemming the remainings.</p>
<div class="highlight"><pre><span class="n">each_word</span><span class="p">(</span><span class="s1">&#39;Hello world! How are you?&#39;</span><span class="p">)</span>

<span class="c1"># =&gt; [&quot;hello&quot;, &quot;world&quot;]</span>

<span class="n">each_word</span><span class="p">(</span><span class="s1">&#39;Lots of dogs, lots of cats! </span>
<span class="s1">  This is the information highway&#39;</span><span class="p">)</span>

<span class="c1"># =&gt; [&quot;lot&quot;, &quot;dog&quot;, &quot;lot&quot;, &quot;cat&quot;, &quot;inform&quot;, &quot;highwai&quot;]</span>

<span class="n">each_word</span><span class="p">(</span><span class="s2">&quot;I don&#39;t really get what you want to</span>
<span class="s2">  accomplish. There is a class TestEval2, you can do test_eval2 =</span>
<span class="s2">  TestEval2.new afterwards. And: class A ... end always yields nil, so</span>
<span class="s2">  your output is ok I guess ;-)&quot;</span><span class="p">)</span>

<span class="c1"># =&gt; [&quot;really&quot;, &quot;want&quot;, &quot;accomplish&quot;, &quot;class&quot;,</span>
<span class="c1">#     &quot;testeval&quot;, &quot;test&quot;, &quot;eval&quot;, &quot;testeval&quot;, &quot;new&quot;, </span>
<span class="c1">#     &quot;class&quot;, &quot;end&quot;, &quot;yields&quot;, &quot;nil&quot;, &quot;output&quot;, </span>
<span class="c1">#     &quot;ok&quot;, &quot;guess&quot;]</span>
</pre></div>
<p><strong>NOTE:</strong> depending on the size of your training data, this may not be
a good idea. Stemming is useful in the beginning when you don&#39;t have a
lot of data. Otherwise consider &ldquo;<em>house</em>&rdquo; and &ldquo;<em>housing</em>&rdquo; &hellip; the
former is used less frequently in a spammy context then the later.</p>

<h3>2.5. Implementation Guidelines</h3>

<p>When classifying emails for spam, it is a good idea to be sure that a
certain message is a spam message, otherwise users may get pissed by
too many false positives.</p>

<p>Therefore it is a good idea to have <em>thresholds</em>. This is how my
implementation looks like:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kp">nil</span><span class="p">)</span>
  <span class="c1"># Find the category with the highest probability</span>

  <span class="n">max_prob</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">0</span>
  <span class="n">best</span> <span class="o">=</span> <span class="kp">nil</span>

  <span class="n">scores</span> <span class="o">=</span> <span class="n">cat_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
    <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
      <span class="n">max_prob</span> <span class="o">=</span> <span class="n">prob</span>
      <span class="n">best</span> <span class="o">=</span> <span class="n">cat</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="c1"># Return the default category in case the threshold condition was</span>
  <span class="c1"># not met. For example, if the threshold for :spam is 1.2</span>
  <span class="c1">#</span>
  <span class="c1">#    :spam =&gt; 0.73, :ham =&gt; 0.40  (OK)</span>
  <span class="c1">#    :spam =&gt; 0.80, :ham =&gt; 0.70  (Fail, :ham is too close)</span>

  <span class="k">return</span> <span class="n">default</span> <span class="k">unless</span> <span class="n">best</span>
  <span class="n">threshold</span> <span class="o">=</span> <span class="vi">@thresholds</span><span class="o">[</span><span class="n">best</span><span class="o">]</span> <span class="o">||</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span>

  <span class="n">scores</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">score</span><span class="o">|</span>
    <span class="n">cat</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">score</span>
    <span class="k">next</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">best</span>
    <span class="k">return</span> <span class="n">default</span> <span class="k">if</span> <span class="n">prob</span> <span class="o">*</span> <span class="n">threshold</span> <span class="o">&gt;</span> <span class="n">max_prob</span>
  <span class="k">end</span>

  <span class="k">return</span> <span class="n">best</span>
<span class="k">end</span>
</pre></div>
<h2>Final Words</h2>

<p>My example involved spam classification, however this is not how
modern spam classifiers work btw. Because the independence assumptions
are often inaccurate, this type of classifier can be gamed by spammers
to trigger a lot of false positives, which will make the user turn the
feature off eventually.</p>

<p>But it is general purpose, being good enough not only for spam
detection, but also for lots of other use-cases and it&#39;s enough to get
you started.</p>

  </div>

  <footer>
    <div id="other-articles">
      <h2>Recent Articles</h2>

      <ul class="posts">
		
	<li> 
	  <time datetime="2012-11-07">
	    2012-11-07 &raquo;
	  </time>
	  <a href="/blog/2012/11/07/notes-javascript-development.html" rel="prefetch related">Notes On Javascript Client-side Development</a>
	</li>      
		
	<li> 
	  <time datetime="2012-11-02">
	    2012-11-02 &raquo;
	  </time>
	  <a href="/blog/2012/11/02/scala-functional-programming-type-classes.html" rel="prefetch related">On Scala, Functional Programming and Type-Classes</a>
	</li>      
		
	<li> 
	  <time datetime="2012-07-02">
	    2012-07-02 &raquo;
	  </time>
	  <a href="/blog/2012/07/02/love-scala.html" rel="prefetch related">Things I Love About Scala</a>
	</li>      
		
	<li> 
	  <time datetime="2012-01-16">
	    2012-01-16 &raquo;
	  </time>
	  <a href="/blog/2012/01/16/cosine-similarity-euclidean-distance.html" rel="prefetch related">Data Mining: Finding Similar Items and Users</a>
	</li>      
		
	<li> 
	  <time datetime="2012-01-05">
	    2012-01-05 &raquo;
	  </time>
	  <a href="/blog/2012/01/05/blogging-for-hackers.html" rel="prefetch related">Blogging Platform for Hackers</a>
	</li>      
		
	<li> 
	  <time datetime="2011-12-15">
	    2011-12-15 &raquo;
	  </time>
	  <a href="/blog/2011/12/15/crawling-the-android-marketplace-155200-apps.html" rel="prefetch related">Crawling the Android Marketplace</a>
	</li>      
		
	<li> 
	  <time datetime="2011-11-29">
	    2011-11-29 &raquo;
	  </time>
	  <a href="/blog/2011/11/29/earning-money-as-an-amazon-affiliate.html" rel="prefetch related">Earning Money as an Amazon Affiliate</a>
	</li>      
	
      </ul>
    </div>

    <div id="contributions">
      <div id="disqus_thread"></div>
      <script type="text/javascript">	
	var disqus_shortname = 'alexnorg';
	var disqus_url = 'http://bionicspirit.com/blog/2012/02/09/howto-build-naive-bayes-classifier.html';

	/* * * DON'T EDIT BELOW THIS LINE * * */
	(function() {
	var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
      </script>
      <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </footer>
</article>

    </div>
  </div>

  <div id="footer-container">
    <footer>
      <div class="contact">
	&copy; 2013 Alexandru Nedelcu
	<br />
	Some rights reserved (<a href="http://creativecommons.org/licenses/by-nc/3.0/" rel="license">CC BY-NC 3.0</a>)
    <!--sse-->
	<br />
	contact [at-] bionicspirit (-dot) com
    <!--/sse-->
      </div>

      <div class="rss">
	<a href="https://twitter.com/alex_ndc" target="_blank" title="Follow me on Twitter (@alex_ndc)">
	  <img alt="Follow me on Twitter (@alex_ndc)" supported_extensions="[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;, &quot;.bmp&quot;, &quot;.gif&quot;]" width="32" height="32" src="../../../../assets/img/twitter-2856d310.png" />
	</a>
      </div>
    </footer>
  </div>
</body>
</html>
