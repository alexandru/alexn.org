<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/Article">
<head>
  <title>Why I Find Heroku Suboptimal</title>

  <meta charset="utf-8">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width,initial-scale=1">
    
  <link href="http://bionicspirit.com/rss" rel="alternate" title="Alexandru Nedelcu" type="application/atom+xml">
  <link rel="shortcut icon" href="//www.bionicspirit.com/assets/images/faviconred3.ico"> 
  <link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="//www.bionicspirit.com/assets/all-8aba01c02.css" type="text/css">

  <!-- Google+ / Facebook optimations -->
  <link rel="image_src" href="//www.bionicspirit.com/assets/images/picture_alex.jpg">
  <!-- not really sure about this -->
  
  <link href="https://plus.google.com/112639155372207976835/" rel="author">
  
  <!-- END: Google+ / Facebook optimations -->

  <!-- Google Analytics -->
<script language="javascript" type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27605864-1']);
  // to enable tracking (and thus cookies set) for all subdomains
  //_gaq.push(['_setDomainName', 'bionicspirit.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

</head>
<body>
  <div id="header-container">
    <header>
      <h1 id="title">Bionic Spirit</h1>

      <nav>
	  <a href="/">bionicspirit.com</a>
	  <a class="extra" href="/pages/archive.html">archive</a>
	  <a class="extra" href="/pages/about.html">about</a>
	  <a class="extra" href="/pages/subscribe.html">subscribe</a>
	  <a href="http://github.com/alexandru" class="github" title="Fork me on GitHub"><span>Fork me on GitHub</span></a>
      </nav>
    </header>
  </div>

  <div id="main-container">
    <div id="main">
      <article id="post">
  <header>
    <h1 itemprop="name">Why I Find Heroku Suboptimal</h1>
    <div id="meta">
      <div class="post-date">Published: 23 Oct 2011</div>
    </div>
  </header>

  <div id="content">
    <p>
  I love freebies. I often find myself compelled to search for the
  best price / convenience ratio, and from this perspective you cannot
  really argue against something offered for free. And yet, here I am
  bitching and moaning about Heroku.
</p>

<p>
  Heroku provides a free-quota that's a LOT more reasonable than all
  the shitty PHP hosting offerings out there. And when time comes to
  scale, it lets you scale nicely for a price.
</p>

<p>
  Normally you develop your app on your localhost (which is like this
  warm and cozy place for all developers, <i>no place like
  127.0.0.1</i> and all that), but then you want to deploy. You have
  to get out of your comfort zone and face the jungle and it's a true
  jungle out there, filled with shitty / underpowered and expensive
  hosting offerings. If going for a normal VPS, you'll have to
  configure your application server, your database server, your
  webserver that sits on top, maybe a reverse proxy cache, a memcached
  instance or two, a load balancer, a firewall, an email server and it
  goes on and on. And if going for a classic shared-hosting
  environment, then God help you.
</p>

<p>
  There's a reason children with happy childhoods don't want to grow
  up - the world is an ugly and scary place.
</p>

<h2>git push heroku master</h2>

<p>
  Heroku is great. It basically allows you to avoid growing-up. The
  deployment itself couldn't be simpler, and when browsing their web
  interface for available add-ons, I feel like a child in a
  candy-store.
</p>

<p>
  Basically you start with a free worker, to which you can add other
  "free" services, like a 5MB PostgreSql database and a 5MB Memcached
  instance, allowing you to prototype stuff. They even have plugins
  from third-parties that give you freebies, like a 250MB CouchDB, or
  a 240MB MongoDB. Then as you grow, you start adding more and more
  resources as needed. This has been labeled as <i>platform as a
  service</i> and it's what the cool kids are talking about these
  days.

  Heck, there are people that are living within that free-quota
  without problems. One such example that I know of is <a
  href="http://tzigla.com" target="_blank">http://tzigla.com</a>
  ... or it was last time I talked to the authors, both acquaintances
  of mine, and Cristi described how he ended-up doing lots of
  workarounds to get around limitations and he was really excited
  about how everything fell into place.
</p>

<p>
  But as I was sitting there admiring their determination and skill, I
  started wondering why the hell haven't they rented a normal VPS?
</p>

<p>
  I mean really, if you end up pulling all kinds of crap to get around
  limitations, wouldn't it be better to just pay up? And if you're
  short on cash or you're the kind of entrepreneur that likes to spend
  frugally, then wouldn't you be better just renting a normal VPS? I
  asked him just that of course, and his reply was basically:
</p>

<p class="dialog">
  <i>I hate to do sys-admin stuff, installing and upgrading packages and all that</i>
</p>

<p>
  But it doesn't have to be that way. It's really not that hard. The
  reason for these feelings is the Ubuntu I have had installed on my
  primary laptop for 5 years already. Once you work with Ubuntu or
  your favorite Linux distribution, every day, configuring a
  web-server for starters is something like a half-an-hour chore. Or
  let's say 1 hour, and then it's done. And you don't have to worry
  about it again.
</p>

<p>
  <b>And there are disadvantages to Heroku</b>, lots of them: that's
  because you lose control and end up on top of a platform that's
  designed as a common denominator to appeal to all needs in an
  equally substandard manner.
</p>

<h2>Example 1: Nginx</h2>

<p>
  Nginx is a freakishly fast web server that consumes really few
  resources. Its main appeal is in serving static files and you do
  have static files to serve. When you grow you may want to move those
  static files to a CDN, like CloudFront, which serves content from
  locations closer to the actual users, but for serving css/javascript
  and small images - a properly configured Nginx is all you need. And
  you can't really move any files served from your main domain to a
  CDN (like HTML content).
</p>

<p>
  You can also be smart about semi-static pages in Rails - you can
  cache the output inside the <i>public/</i> directory to be served by
  Nginx. And if you still want to hit your controller on every
  request, like when doing A/B Testing on a page, you can send an
  <i>X-Accel-Redirect</i> header in your response to Nginx and let
  Nginx to the actual content streaming for you. You can also instruct
  Nginx to serve files from different locations, based on certain
  variables like the domain name, thus avoiding hitting the Rails
  application server on every request.
</p>

<p>
  There's a lot you can do with Nginx if you're on a budget, and yet
  this is not possible within Heroku ... which even though it may use
  Nginx as an http reverse proxy, it certainly doesn't use it for
  serving static files. All files are thus served by hitting the Rails
  server, unless Varnish is involved.  
</p>

<h2>Example 2: Varnish</h2>

<p>
  <a href="https://www.varnish-cache.org/">Varnish</a> is described as
  being a <i>web application accelerator</i> and the things it can do
  are truly mind-blowing.
</p>

<p>
  Varnish sits in front of your application servers. It can do
  <i>load-balancing</i> for you with extreme efficiency, although
  that's not its main purpose. Its main purpose is to cache content.
</p>

<p>
  When caching content you have an extreme freedom to specify the Key
  for fetching cached items. You can use anything when instructing
  Varnish on what and how to cache, like cookies or the user's IP or
  any HTTP header. Do you want to also cache content for logged-in
  users, even though that content is slightly different from user to
  user? Not a problem.  The configuration language is also extremely
  flexible, allowing you to tap in the request pipeline with any
  custom behavior you want.  The performance of Varnish coupled with
  this extreme flexibility is what makes it great. It also has this
  uncanny ability to reload its configuration without restarting or
  dropping active connections.
</p>

<p>
  Heroku has Varnish in its stable stack, called Bamboo. But you
  cannot configure it. The configuration is the same for everybody
  ... you basically set expiry headers on your response, Varnish
  caches it for you and the cache gets invalidated on every new
  deployment.
</p>

<p>
  This is actually good and has given rise to the famous Heroku
  use-case: hosting mostly static websites on it. But Varnish can be
  much more than that, otherwise it kind of gets in your way, and
  surprise - Heroku is pulling Varnish out of the configuration,
  starting with the new Celadon Cedar stack. This is because Varnish
  gets in the way of their ambitious plans: to make heroku
  platform-agnostic, thus adding support for Node.js and long-pooling.
</p>

<p>
  The now recommended alternative for serving cached static content is
  to use Rack::Cache in combination with their Memcached add-on. But
  this sucks because (1) it hits the Rails server on every request and
  in the free plan you only have a single process to serve those
  requests + (2) the free plan for Memcached is only 5MB.
</p>

<h2>Example 3: asynchronous jobs</h2>

<p>
  One common-sense approach to not having a sluggish web interface is
  to get slow code out of your HTTP process. Lots of libraries and
  plugins are available for all web frameworks, like
  <i>delayed_job</i> for Rails or <i>Celery</i> for Django. And you
  can just write your own half-baked jobs queue and shove it in your
  cron.
</p>

<p>
  You cannot have asynchronous jobs using Heroku's free plan. You must
  get an extra dyno for that.
</p>

<h2>Price comparison with Linode</h2>

<p>
  The cheapest <a
  href="http://www.linode.com/?r=c7376c22b7853329bfb629a54dc9a843be935c36">Linode
  instance</a> is <b>$20</b> per month, and for starters you can have ...
</p>

<ul>
  <li>1 Nginx server</li>
  <li>2 Passenger/Rails processes</li>
  <li>
    1 worker for processing asynchronous jobs, it can even be a plain
    cron-job ; you do have complete flexibility in configuring
    cron-jobs
  </li>
  <li>
    1 PostgreSQL database, configured for 256MB RAM usage, with 18 GB
    of storage. It's not much, but it isn't <i>shared</i> either and
    does just fine, trust me ... btw, the <a
    href="http://pgmag.org/">PostgreSQL magazine</a> (first issue) has
    an article about configuring/optimizing PostgreSQL's memory usage
  </li>
  <li>
    1 Postfix email server, for bug reports + sending all the spam
    you want (Linode lets you configure reverse DNS lookup, so you can
    have a cheap email server that doesn't trigger spam alerts)
  </li>
  <li>
    ability to serve for any domain you want, including wildcard subdomains
  </li>
  <li>
    your own SSL certificate, for free depending on provider
  </li>
</ul>

<p>
  The equivalent Heroku configuration would cost a minimum of <b>$114
  per month</b>.
</p>

<p>
  So lets say that you're growing and you want to add Ronin, Heroku's
  plan for a database of 1.7 GB <i>hot data set</i> (whatever the fuck
  that means). That will cost you a whooping <b>$200 per month</b>
  extra, versus <b>$80</b> for a 2GB of RAM instance on Linode, or
  even better, $160 for a 4GB of RAM instance.
</p>

<h2>Linode sucks too, but that's besides the point</h2>

<p>
  You lose the ability to increase your dynos in response to traffic
  surges. On the other hand you'll be amazed at how much you can
  squeeze out of your rented hardware and if a properly configured
  setup fails to serve, then the problems you have probably can't be
  solved by just adding extra web servers.
</p>

<p>
  Really, do some reading on why Reddit is down so often. Do some
  reading on why Amazon's EBS is completely unreliable for databases
  (btw, Heroku does use EBS and they've also had their share of
  downtime due to AWS experiencing problems).
</p>

<p>
  Stop fearing the penguin and start configuring your own damn
  servers. As with everything that's actually worth it in life (like
  having children of your own), it's hard at first but the return of
  investment will be tenfold.
</p>

<p>
  <b>PS:</b> I'm obviously advertising <a
  href="http://www.linode.com/?r=c7376c22b7853329bfb629a54dc9a843be935c36">Linode</a>
  here. Links to it contain my affiliate tracking code, and if you
  become a customer you'll give me $20 worth of credit, which helps me
  pay for this blog's hosting (what can I say, I'm a cheap
  bastard). On the other hand this does express my genuine view of
  these services.
</p>



    <h2>Subscribe</h2>

    <p>
      If you liked this article, subscribe <a
      href="/pages/subscribe.html">by Email</a> or by RSS.
    </p>

    <p>
      Thanks,
    </p>
  </div>

  <footer>
    <div id="other-articles">
      <h2>Other Articles</h2>

      <ul class="posts">
	
	
<li> 
  <time datetime="2012-01-05T00:00:00+02:00">05 Jan 2012 &raquo;</time>
  <a href="/blog/2012/01/05/blogging-for-hackers.html" rel="prefetch related">Blogging Platform for Hackers</a>
</li>


	
	
<li> 
  <time datetime="2011-10-29T00:00:00+03:00">29 Oct 2011 &raquo;</time>
  <a href="/blog/2011/10/29/how-i-use-flickr.html" rel="prefetch related">How I Use Flickr: For Backup</a>
</li>


	
	
<li> 
  <time datetime="2012-02-09T00:00:00+02:00">09 Feb 2012 &raquo;</time>
  <a href="/blog/2012/02/09/howto-build-naive-bayes-classifier.html" rel="prefetch related">How To Build a Naive Bayes Classifier</a>
</li>


	
	
<li> 
  <time datetime="2012-01-16T00:00:00+02:00">16 Jan 2012 &raquo;</time>
  <a href="/blog/2012/01/16/cosine-similarity-euclidean-distance.html" rel="prefetch related">Data Mining: Finding Similar Items and Users</a>
</li>


	
	
<li> 
  <time datetime="2011-12-15T00:00:00+02:00">15 Dec 2011 &raquo;</time>
  <a href="/blog/2011/12/15/crawling-the-android-marketplace-155200-apps.html" rel="prefetch related">Crawling the Android Marketplace</a>
</li>


	
      </ul>
    </div>

    
    <div id="contributions">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
	var disqus_shortname = 'alexnorg'; 

	/* * * DON'T EDIT BELOW THIS LINE * * */
	(function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
      </script>
      <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
    
  </footer>
</article>


    </div>
  </div>

  <div id="footer-container">
    <footer>
      <div class="contact">
	&copy; 2012 Alexandru Nedelcu
	<br />
	Some rights reserved (<a href="http://creativecommons.org/licenses/by-nc/3.0/" rel="license">CC BY-NC 3.0</a>)
    <!--sse-->
	<br />
	<a href="mailto:&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#098;&#105;&#111;&#110;&#105;&#099;&#115;&#112;&#105;&#114;&#105;&#116;&#046;&#099;&#111;&#109;">&#099;&#111;&#110;&#116;&#097;&#099;&#116;&#064;&#098;&#105;&#111;&#110;&#105;&#099;&#115;&#112;&#105;&#114;&#105;&#116;&#046;&#099;&#111;&#109;</a>
    <!--/sse-->
      </div>

      <div class="rss">
	<a href="https://twitter.com/alex_ndc" target="_blank" title="Follow me on Twitter (@alex_ndc)">
	  <img src="//www.bionicspirit.com/assets/images/twitter.png" alt="Follow me on Twitter (@alex_ndc)" />
	</a>
      </div>
    </footer>
  </div>


  <!--[if lt IE 7 ]>
  <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.2/CFInstall.min.js"></script>
  <script>window.attachEvent("onload",function(){CFInstall.check({mode:"overlay"})})</script>
  <![endif]-->

  <script type="text/javascript">
    function recordOutboundLink(link, category, action) {
      try {
        var myTracker=_gat._getTrackerByName();
	_gaq.push(['myTracker._trackEvent', ' + category + ', ' + action + ']);
	setTimeout('document.location = "' + link.href + '"', 100);
      }catch(err){}
    }    
  </script>
</body>
</html>

